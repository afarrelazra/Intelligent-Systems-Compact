{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc1aeee1-299b-43e0-aca7-0593c3ffa5f1",
   "metadata": {},
   "source": [
    "Simple Digit Image Generator Using GAN(Generative Adversarial Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b978fb78-cbbd-4d95-a710-7007a57462e6",
   "metadata": {},
   "source": [
    "1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5345e9ea-43c7-40fe-9cda-98fa37f55af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c747f2b7-b775-4ae4-8a1e-cb4952d35e28",
   "metadata": {},
   "source": [
    "-TensorFlow and Keras: Used for building and training neural networks.\n",
    "\n",
    "-NumPy: Used for numerical operations and handling arrays.\n",
    "\n",
    "-Matplotlib: Used for plotting and visualizing generated images.\n",
    "\n",
    "-Load Model: Used for loading pre-trained models from disk.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0272d39a-c852-4f14-8da3-f42a7b855b5c",
   "metadata": {},
   "source": [
    "2. Build the Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bf9e16d-4dfa-4ad6-8c1f-1221556a0227",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_generator(latent_dim, num_classes):\n",
    "    noise = layers.Input(shape=(latent_dim,))\n",
    "    label = layers.Input(shape=(num_classes,))\n",
    "    model_input = layers.concatenate([noise, label])\n",
    "\n",
    "    x = layers.Dense(128)(model_input)\n",
    "    x = layers.LeakyReLU(negative_slope=0.2)(x)\n",
    "    x = layers.Dense(256)(x)\n",
    "    x = layers.LeakyReLU(negative_slope=0.2)(x)\n",
    "\n",
    "    x = layers.Dense(28 * 28 * 1, activation='tanh')(x)\n",
    "    output = layers.Reshape((28, 28, 1))(x)\n",
    "\n",
    "    model = Model([noise, label], output)\n",
    "    return model\n",
    "\n",
    "# Define dimensions and number of classes\n",
    "latent_dim = 100  # Size of the noise vector\n",
    "num_classes = 10  # Number of digit classes (0-9)\n",
    "\n",
    "# Instantiate the generator\n",
    "generator = build_generator(latent_dim, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57effa8-ff88-4400-93db-f6b760964062",
   "metadata": {},
   "source": [
    "-Latent Dimension: Represents the noise input, which is used to generate random images.\n",
    "-Label Input: The digit class (0-9) that the generator should learn to produce."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662ccb79-4630-41ff-845e-a3d0045574c0",
   "metadata": {},
   "source": [
    "3. Build the Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd28cf6e-16df-4079-b6c1-e8bb50f567d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(img_shape, num_classes):\n",
    "    img = layers.Input(shape=img_shape)\n",
    "    label = layers.Input(shape=(num_classes,))\n",
    "\n",
    "    label_embedding = layers.Dense(np.prod(img_shape))(label)\n",
    "    label_embedding = layers.Reshape(img_shape)(label_embedding)\n",
    "\n",
    "    combined_input = layers.concatenate([img, label_embedding])\n",
    "\n",
    "    x = layers.Flatten()(combined_input)\n",
    "    x = layers.Dense(512)(x)\n",
    "    x = layers.LeakyReLU(negative_slope=0.2)(x)\n",
    "    x = layers.Dense(256)(x)\n",
    "    x = layers.LeakyReLU(negative_slope=0.2)(x)\n",
    "\n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model([img, label], x)\n",
    "    return model\n",
    "\n",
    "# Define the image shape (28x28 pixels, 1 channel)\n",
    "img_shape = (28, 28, 1)\n",
    "\n",
    "# Instantiate the discriminator\n",
    "discriminator = build_discriminator(img_shape, num_classes)\n",
    "discriminator.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbccf0b-ed7f-4ede-84fa-71d2cf8a877b",
   "metadata": {},
   "source": [
    "-Image Input: The image to be classified as real or fake.\n",
    "\n",
    "-Label Embedding: Embeds the label into the same shape as the image to combine them.\n",
    "\n",
    "-Discriminator Output: Produces a single value, indicating whether the image is real (1) or fake (0).\n",
    "\n",
    "4. Combine Generator and Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f517d63-d417-462a-9e5d-c54667c116e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ functional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">248,720</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
       "│                               │                           │                 │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ functional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">943,537</span> │ functional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n",
       "│                               │                           │                 │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ functional (\u001b[38;5;33mFunctional\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m248,720\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
       "│                               │                           │                 │ input_layer_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ functional_1 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │         \u001b[38;5;34m943,537\u001b[0m │ functional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n",
       "│                               │                           │                 │ input_layer_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,192,257</span> (4.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,192,257\u001b[0m (4.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,192,257</span> (4.55 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,192,257\u001b[0m (4.55 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine the generator and discriminator models\n",
    "noise = layers.Input(shape=(latent_dim,))\n",
    "label = layers.Input(shape=(num_classes,))\n",
    "generated_img = generator([noise, label])\n",
    "validity = discriminator([generated_img, label])\n",
    "\n",
    "# Create the combined model to train the generator\n",
    "combined = Model([noise, label], validity)\n",
    "combined.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "combined.summary()  # Display the model architecture\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2288304-f3d8-4644-b2ee-5f4bfa53e578",
   "metadata": {},
   "source": [
    "-Combined Model: The generator and discriminator are combined to create a model that updates the generator based on the discriminator's feedback.\n",
    "\n",
    "5. Load and Preprocess the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b275c47-fb99-4e7d-93dd-83497b212b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the MNIST dataset\n",
    "(X_train, y_train), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5  # Normalize images to [-1, 1]\n",
    "X_train = np.expand_dims(X_train, axis=-1)  # Expand dimensions to match input shape of (28, 28, 1)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=num_classes)  # One-hot encode the labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892150c1-8716-410f-9644-6dd39e8e3c9c",
   "metadata": {},
   "source": [
    "-MNIST Dataset: A dataset of handwritten digits commonly used for training image processing systems.\n",
    "\n",
    "-Normalization: Scales the pixel values to be between -1 and 1 for better training performance.\n",
    "\n",
    "6. Train the GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a463f944-d985-4c61-92da-b0b02168b291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 1/100 - D loss: 0.6985 - G loss: 0.7397\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000001B5799FDC60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x000001B50CDE3920> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Epoch 2/100 - D loss: 0.7100 - G loss: 0.9269\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 3/100 - D loss: 0.9822 - G loss: 1.2230\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 4/100 - D loss: 1.2628 - G loss: 1.4772\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 5/100 - D loss: 1.4787 - G loss: 1.6443\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 6/100 - D loss: 1.6057 - G loss: 1.7166\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 7/100 - D loss: 1.6444 - G loss: 1.7043\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 8/100 - D loss: 1.6023 - G loss: 1.6139\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step\n",
      "Epoch 9/100 - D loss: 1.4952 - G loss: 1.4714\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step\n",
      "Epoch 10/100 - D loss: 1.3663 - G loss: 1.3374\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 11/100 - D loss: 1.2746 - G loss: 1.2548\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step\n",
      "Epoch 12/100 - D loss: 1.2066 - G loss: 1.2129\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 13/100 - D loss: 1.1880 - G loss: 1.2117\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 14/100 - D loss: 1.1927 - G loss: 1.2185\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 15/100 - D loss: 1.1957 - G loss: 1.2149\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 16/100 - D loss: 1.1859 - G loss: 1.1961\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 17/100 - D loss: 1.1612 - G loss: 1.1626\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 18/100 - D loss: 1.1249 - G loss: 1.1204\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step\n",
      "Epoch 19/100 - D loss: 1.0837 - G loss: 1.0767\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step\n",
      "Epoch 20/100 - D loss: 1.0437 - G loss: 1.0369\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step\n",
      "Epoch 21/100 - D loss: 1.0075 - G loss: 1.0021\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Epoch 22/100 - D loss: 0.9764 - G loss: 0.9734\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step\n",
      "Epoch 23/100 - D loss: 0.9497 - G loss: 0.9474\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 24/100 - D loss: 0.9238 - G loss: 0.9202\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step\n",
      "Epoch 25/100 - D loss: 0.8965 - G loss: 0.8915\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 26/100 - D loss: 0.8687 - G loss: 0.8633\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 27/100 - D loss: 0.8421 - G loss: 0.8371\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 28/100 - D loss: 0.8179 - G loss: 0.8140\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step\n",
      "Epoch 29/100 - D loss: 0.7969 - G loss: 0.7940\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 30/100 - D loss: 0.7781 - G loss: 0.7757\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step\n",
      "Epoch 31/100 - D loss: 0.7605 - G loss: 0.7581\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 32/100 - D loss: 0.7436 - G loss: 0.7411\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 33/100 - D loss: 0.7271 - G loss: 0.7245\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step\n",
      "Epoch 34/100 - D loss: 0.7116 - G loss: 0.7095\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 35/100 - D loss: 0.6980 - G loss: 0.6968\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step\n",
      "Epoch 36/100 - D loss: 0.6866 - G loss: 0.6862\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step\n",
      "Epoch 37/100 - D loss: 0.6760 - G loss: 0.6753\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 38/100 - D loss: 0.6646 - G loss: 0.6630\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 39/100 - D loss: 0.6522 - G loss: 0.6500\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step\n",
      "Epoch 40/100 - D loss: 0.6391 - G loss: 0.6365\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 41/100 - D loss: 0.6260 - G loss: 0.6233\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step\n",
      "Epoch 42/100 - D loss: 0.6134 - G loss: 0.6110\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 43/100 - D loss: 0.6020 - G loss: 0.6002\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step\n",
      "Epoch 44/100 - D loss: 0.5918 - G loss: 0.5904\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step\n",
      "Epoch 45/100 - D loss: 0.5824 - G loss: 0.5811\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step\n",
      "Epoch 46/100 - D loss: 0.5737 - G loss: 0.5727\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step\n",
      "Epoch 47/100 - D loss: 0.5656 - G loss: 0.5647\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 48/100 - D loss: 0.5580 - G loss: 0.5573\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 49/100 - D loss: 0.5503 - G loss: 0.5490\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 50/100 - D loss: 0.5419 - G loss: 0.5403\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 51/100 - D loss: 0.5337 - G loss: 0.5325\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step\n",
      "Epoch 52/100 - D loss: 0.5260 - G loss: 0.5247\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step\n",
      "Epoch 53/100 - D loss: 0.5182 - G loss: 0.5166\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 54/100 - D loss: 0.5101 - G loss: 0.5085\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 55/100 - D loss: 0.5024 - G loss: 0.5009\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step\n",
      "Epoch 56/100 - D loss: 0.4949 - G loss: 0.4934\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 57/100 - D loss: 0.4877 - G loss: 0.4863\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 58/100 - D loss: 0.4819 - G loss: 0.4813\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 59/100 - D loss: 0.4756 - G loss: 0.4739\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 60/100 - D loss: 0.4683 - G loss: 0.4666\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 61/100 - D loss: 0.4617 - G loss: 0.4607\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 62/100 - D loss: 0.4556 - G loss: 0.4543\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 63/100 - D loss: 0.4492 - G loss: 0.4477\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 64/100 - D loss: 0.4429 - G loss: 0.4418\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 65/100 - D loss: 0.4373 - G loss: 0.4363\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 66/100 - D loss: 0.4318 - G loss: 0.4307\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 67/100 - D loss: 0.4262 - G loss: 0.4250\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step\n",
      "Epoch 68/100 - D loss: 0.4211 - G loss: 0.4204\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 69/100 - D loss: 0.4162 - G loss: 0.4151\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 70/100 - D loss: 0.4111 - G loss: 0.4100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 71/100 - D loss: 0.4062 - G loss: 0.4054\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 72/100 - D loss: 0.4018 - G loss: 0.4010\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 73/100 - D loss: 0.3974 - G loss: 0.3965\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step\n",
      "Epoch 74/100 - D loss: 0.3928 - G loss: 0.3917\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step\n",
      "Epoch 75/100 - D loss: 0.3885 - G loss: 0.3879\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 76/100 - D loss: 0.3849 - G loss: 0.3844\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 77/100 - D loss: 0.3808 - G loss: 0.3797\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 78/100 - D loss: 0.3765 - G loss: 0.3758\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 79/100 - D loss: 0.3736 - G loss: 0.3738\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 80/100 - D loss: 0.3705 - G loss: 0.3695\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 81/100 - D loss: 0.3663 - G loss: 0.3653\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step\n",
      "Epoch 82/100 - D loss: 0.3625 - G loss: 0.3619\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step\n",
      "Epoch 83/100 - D loss: 0.3592 - G loss: 0.3587\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 84/100 - D loss: 0.3556 - G loss: 0.3547\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 85/100 - D loss: 0.3517 - G loss: 0.3507\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step\n",
      "Epoch 86/100 - D loss: 0.3482 - G loss: 0.3477\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 87/100 - D loss: 0.3456 - G loss: 0.3454\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 88/100 - D loss: 0.3427 - G loss: 0.3419\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 89/100 - D loss: 0.3392 - G loss: 0.3386\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 90/100 - D loss: 0.3367 - G loss: 0.3367\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step\n",
      "Epoch 91/100 - D loss: 0.3343 - G loss: 0.3338\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 92/100 - D loss: 0.3312 - G loss: 0.3305\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 93/100 - D loss: 0.3286 - G loss: 0.3285\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 94/100 - D loss: 0.3260 - G loss: 0.3253\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step\n",
      "Epoch 95/100 - D loss: 0.3230 - G loss: 0.3224\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 96/100 - D loss: 0.3207 - G loss: 0.3206\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 97/100 - D loss: 0.3181 - G loss: 0.3173\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1000us/step\n",
      "Epoch 98/100 - D loss: 0.3149 - G loss: 0.3142\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 99/100 - D loss: 0.3155 - G loss: 0.3184\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Epoch 100/100 - D loss: 0.3160 - G loss: 0.3152\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "epochs = 100  # Reduced for quick demonstration\n",
    "batch_size = 128  # Number of samples per gradient update\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training the discriminator\n",
    "    idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "    imgs, labels = X_train[idx], y_train[idx]\n",
    "\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    gen_imgs = generator.predict([noise, labels])\n",
    "\n",
    "    valid_y = np.ones((batch_size, 1))\n",
    "    fake_y = np.zeros((batch_size, 1))\n",
    "\n",
    "    d_loss_real = discriminator.train_on_batch([imgs, labels], valid_y)\n",
    "    d_loss_fake = discriminator.train_on_batch([gen_imgs, labels], fake_y)\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # Training the generator\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    valid_y = np.ones((batch_size, 1))\n",
    "    g_loss = combined.train_on_batch([noise, labels], valid_y)\n",
    "\n",
    "    # Access the first element of d_loss and g_loss if they are lists\n",
    "    d_loss_value = d_loss[0] if isinstance(d_loss, list) else d_loss\n",
    "    g_loss_value = g_loss[0] if isinstance(g_loss, list) else g_loss\n",
    "\n",
    "    # Print progress\n",
    "    print(f'Epoch {epoch+1}/{epochs} - D loss: {d_loss_value:.4f} - G loss: {g_loss_value:.4f}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14235a2-f187-476b-893f-45d444cc2ca7",
   "metadata": {},
   "source": [
    "-Training Loop: The GAN is trained over multiple epochs, updating the discriminator and generator in each iteration.\n",
    "\n",
    "-Discriminator Training: The discriminator is trained on both real and fake images.\n",
    "\n",
    "-Generator Training: The generator is trained to produce images that can fool the discriminator.\n",
    "\n",
    "7. Save the Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5ee419f-196c-4bd1-9fd4-0629d7a0baf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save the models\n",
    "generator.save('generator_model.keras')\n",
    "discriminator.save('discriminator_model.keras')\n",
    "combined.save('combined_model.keras')\n",
    "\n",
    "print(\"Models saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e00796-a510-4745-82c5-cffaf521fcae",
   "metadata": {},
   "source": [
    "-Model Saving: Saves the generator, discriminator, and combined models for later use without retraining.\n",
    "\n",
    "8. Load the Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c50981c-3c62-4e39-a318-b4a313b9e7d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load the models\n",
    "generator = load_model('generator_model.keras')\n",
    "discriminator = load_model('discriminator_model.keras')\n",
    "combined = load_model('combined_model.keras')\n",
    "\n",
    "print(\"Models loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94093ab3-2d45-4a8f-ac5c-2c099cb36c43",
   "metadata": {},
   "source": [
    "-Model Loading: Loads the saved models so they can be used for generating images or further training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c13cb7b-06bf-4284-8cf9-db3925691e32",
   "metadata": {},
   "source": [
    "9. Generate Images with User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae4a26fe-4b09-4bf4-b551-e8ea7b3433a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the digit you want to generate (0-9):  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loaded_generator = load_model('generator_model.keras')\n",
    "\n",
    "# Prompt the user for a digit to generate\n",
    "digit = int(input(\"Enter the digit you want to generate (0-9): \"))\n",
    "label_input = np.zeros((1, num_classes))\n",
    "label_input[0, digit] = 1\n",
    "\n",
    "# Generate images with the loaded generator\n",
    "noise = np.random.normal(0, 1, (1, latent_dim))  # Generate random noise\n",
    "gen_img = loaded_generator.predict([noise, label_input])  # Generate image for the input digit\n",
    "\n",
    "# Rescale the image to [0, 1]\n",
    "gen_img = 0.5 * gen_img + 0.5\n",
    "\n",
    "# Visualize the generated image\n",
    "plt.imshow(gen_img[0, :, :, 0], cmap='gray')\n",
    "plt.title(f'Generated Image of Digit {digit}')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe9f104-64bd-4043-89b8-55dc7acbfea9",
   "metadata": {},
   "source": [
    "-User Prompt: Asks the user to input the digit they want to generate.\n",
    "\n",
    "-Label Creation: Creates a one-hot encoded label for the input digit.\n",
    "\n",
    "-Image Generation: Generates an image using the trained generator based on the user’s input."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
